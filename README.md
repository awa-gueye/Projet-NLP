# ğŸ›ï¸ E-commerce Product Classification

> SystÃ¨me de classification automatique de produits e-commerce utilisant texte et/ou images

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)](https://www.tensorflow.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸ“‹ Table des matiÃ¨res

- [Vue d'ensemble](#vue-densemble)
- [DÃ©mo](#dÃ©mo)
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Architecture](#architecture)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Structure du projet](#structure-du-projet)
- [ModÃ¨les](#modÃ¨les)
- [API](#api)
- [Dashboard](#dashboard)
- [DÃ©ploiement](#dÃ©ploiement)
- [RÃ©sultats](#rÃ©sultats)
- [Contributions](#contributions)
- [Licence](#licence)

##  Vue d'ensemble

Ce projet implÃ©mente un systÃ¨me complet de classification de produits e-commerce capable de prÃ©dire automatiquement la catÃ©gorie d'un produit Ã  partir :
- ğŸ“ **Texte** : Description du produit
- ğŸ–¼ï¸ **Image** : Photo du produit
- ğŸ”— **Multimodal** : Combinaison texte + image

### CatÃ©gories supportÃ©es

| IcÃ´ne | CatÃ©gorie |
|-------|-----------|
| ğŸ‘¶ | Baby Care |
| ğŸ’„ | Beauty and Personal Care |
| ğŸ’» | Computers |
| ğŸ¨ | Home Decor & Festive Needs |
| ğŸ›‹ï¸ | Home Furnishing |
| ğŸ³ | Kitchen & Dining |
| âŒš | Watches |

## DÃ©mo

### Interface Web
![App Screenshot](assets/screenshot_app.png)

### API Endpoints
```bash
# Classification par texte
curl -X POST "http://localhost:8000/predict/text" \
     -H "Content-Type: application/json" \
     -d '{"text": "Montre analogique pour homme avec bracelet en cuir"}'

# Classification par image
curl -X POST "http://localhost:8000/predict/image" \
     -F "file=@product_image.jpg"
```

##  FonctionnalitÃ©s

### Application Web (Streamlit)
- âœ… Interface utilisateur moderne et intuitive
- âœ… Classification texte, image ou multimodale
- âœ… Dashboard analytique avec visualisations interactives
- âœ… Historique des prÃ©dictions
- âœ… Export des donnÃ©es en CSV
- âœ… Mode responsive (desktop/mobile)

### API REST (FastAPI)
- âœ… Endpoints de prÃ©diction (texte, image, multimodal)
- âœ… Documentation auto-gÃ©nÃ©rÃ©e (Swagger/ReDoc)
- âœ… Validation des donnÃ©es avec Pydantic
- âœ… Gestion des erreurs robuste
- âœ… CORS configurÃ©
- âœ… Health check endpoint

### ModÃ¨les
- âœ… **Texte** : SVM avec TF-IDF vectorization
- âœ… **Images** : Transfer Learning (ResNet50, EfficientNetB0)
- âœ… **Multimodal** : Late Fusion avec pondÃ©ration optimisÃ©e

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI  â”‚  â† Interface utilisateur
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    HTTP Requests
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI API   â”‚  â† Serveur REST API
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    Load Models
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ML/DL Models   â”‚  â† ModÃ¨les de classification
â”‚  - Text (SVM)   â”‚
â”‚  - Image (CNN)  â”‚
â”‚  - Multimodal   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

##  Installation

### PrÃ©requis
- Python 3.9+
- pip
- Git

### Clonage du repository
```bash
git clone https://github.com/votre-username/ecommerce-classification.git
cd ecommerce-classification
```

### Installations des dÃ©pendances
```bash
# CrÃ©ationd d'un environnement virtuel
python -m venv venv
source venv/bin/activate  

# Installation des packages
pip install -r requirements.txt
```

## ğŸ® Utilisation

### 1. Lancer l'API
```bash
cd api
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

L'API sera accessible Ã  `http://localhost:8000`
- Documentation Swagger : `http://localhost:8000/docs`
- Documentation ReDoc : `http://localhost:8000/redoc`

### 2. Lancer l'application Streamlit
```bash
cd app
streamlit run streamlit_app.py
```

L'application sera accessible Ã  `http://localhost:8501`

### 3. Utilisation de l'API directement

#### Python
```python
import requests

# Classification texte
response = requests.post(
    "http://localhost:8000/predict/text",
    json={"text": "Montre digitale sport avec GPS"}
)
print(response.json())

# Classification image
with open("product.jpg", "rb") as f:
    response = requests.post(
        "http://localhost:8000/predict/image",
        files={"file": f}
    )
print(response.json())
```

#### cURL
```bash
# Texte
curl -X POST "http://localhost:8000/predict/text" \
     -H "Content-Type: application/json" \
     -d '{"text": "Ordinateur portable 15 pouces"}'

# Image
curl -X POST "http://localhost:8000/predict/image" \
     -F "file=@product.jpg"
```

## Structure du projet

```
Projet_NLP/
â”‚
â”œâ”€â”€ ğŸ“‚ api/                          # API FastAPI
â”‚   â”œâ”€â”€ main.py                      # Point d'entrÃ©e API
â”‚   â”œâ”€â”€ models.py                    # ModÃ¨les Pydantic
â”‚   â”œâ”€â”€ routes/                      # Routes organisÃ©es
â”‚   â”‚   â”œâ”€â”€ predict.py
â”‚   â”‚   â””â”€â”€ health.py
â”‚   â””â”€â”€ config.py                    # Configuration
â”‚
â”œâ”€â”€ ğŸ“‚ app/                          # Application Streamlit
â”‚   â”œâ”€â”€ streamlit_app.py
â”‚
â”œâ”€â”€ ğŸ“‚ models/                       # ModÃ¨les entraÃ®nÃ©s sauvegardÃ©s
â”‚   â”œâ”€â”€ final_best_model.pkl              # ModÃ¨le texte SVM
â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl              # Vectorizer TF-IDF
â”‚   â”œâ”€â”€ cnn_final.keras      # ModÃ¨le image CNN
â”‚   â”œâ”€â”€ label_encoders.pkl           # Label encoder
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/                    # Notebooks Jupyter
â”‚   â”œâ”€â”€ n1_analyse_exploratoire.ipynb
â”‚   â”œâ”€â”€ n2_preprocessing_featuring.ipynb
â”‚   â”œâ”€â”€ n3_modelisation.ipynb
â”‚   â”œâ”€â”€ n4_exploration_features_clustering_images.ipynb
â”‚   â””â”€â”€ n5_deep_learning_classification_images.ipynb
â”‚
â”œâ”€â”€ ğŸ“‚ Data/                         # DonnÃ©es
â”‚   â”œâ”€â”€ Flipkart/                         
â”‚   â”‚   â””â”€â”€ flipkart_com-ecommerce_sample_1050.csv    # DonnÃ©es brutes
â”‚   â”‚     â””â”€â”€ images/      # Images produits
â”‚   â””â”€â”€ processed/                   # DonnÃ©es prÃ©traitÃ©es                     
â”‚
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt              # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ Dockerfile                    # Configuration Docker
â”œâ”€â”€ ğŸ“„ docker-compose.yml            # Docker Compose
â”œâ”€â”€ ğŸ“„ .env.example                  # Variables d'environnement
â”œâ”€â”€ ğŸ“„ .gitignore                    # Fichiers Ã  ignorer
â”œâ”€â”€ ğŸ“„ LICENSE                       # Licence
â””â”€â”€ ğŸ“„ README.md                     # Ce fichier
```

## ğŸ¤– ModÃ¨les

### ModÃ¨le Texte (TF-IDF + SVM)

**Architecture :**
```
Input Text
    â†“
[Preprocessing]
    â†“
[TF-IDF Vectorization]
    â†“
[SVM Classifier (RBF kernel)]
    â†“
Output (7 classes)
```

**Performances :**
- Accuracy : **94.94%**
- F1-Score : **0.949**
- Precision : **0.94**
- Recall : **0.9494**

### ModÃ¨le Image (Deep Learning)

**Architecture ResNet50 :**
```
Input Image (224x224x3)
    â†“
[ResNet50 base (frozen layers)]
    â†“
[GlobalAveragePooling2D]
    â†“
[Dense(512) + BatchNorm + Dropout(0.5)]
    â†“
[Dense(256) + BatchNorm + Dropout(0.4)]
    â†“
[Dense(7, softmax)]
```

**Performances :**
- Accuracy : **0.6250**
- F1-Score : **0.6202**
- Training : 50 epochs with early stopping
- Data augmentation : rotation, flip, zoom, shear

### Fusion Multimodale

**StratÃ©gie : Late Fusion**
```python
P_final = Î± Ã— P_text + (1-Î±) Ã— P_image

oÃ¹ Î± = 0.6 (optimisÃ©)
```

## ğŸ”Œ API

### Endpoints disponibles

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| GET | `/` | Informations API |
| GET | `/health` | Health check |
| GET | `/categories` | Liste catÃ©gories |
| POST | `/predict/text` | Classification texte |
| POST | `/predict/image` | Classification image |
| POST | `/predict/multimodal` | Classification combinÃ©e |

### Exemples de rÃ©ponse

```json
{
  "predicted_class": "Watches",
  "confidence": 0.8523,
  "probabilities": {
    "Baby Care": 0.0234,
    "Beauty and Personal Care": 0.0456,
    "Computers": 0.0123,
    "Home Decor & Festive Needs": 0.0289,
    "Home Furnishing": 0.0156,
    "Kitchen & Dining": 0.0219,
    "Watches": 0.8523
  }
}
```

## ğŸ“Š Dashboard

Le dashboard analytique offre :

### KPIs
- ğŸ“ˆ Nombre total de prÃ©dictions
- ğŸ¯ Confiance moyenne
- ğŸ† CatÃ©gorie dominante
- ğŸ“Š Modes utilisÃ©s

### Visualisations
- ğŸ¥§ Distribution des catÃ©gories (pie chart)
- ğŸ“Š Confiance par catÃ©gorie (bar chart)
- â±ï¸ Ã‰volution temporelle (line chart)
- ğŸ“‹ Tableau dÃ©taillÃ© de l'historique

### FonctionnalitÃ©s
- Export CSV de l'historique
- Filtres interactifs
- Graphiques Plotly interactifs

## â˜ï¸ DÃ©ploiement

### Option 1: Streamlit Cloud

```bash
# 1. Push sur GitHub
git push origin main

# 2. Se connecter Ã  https://share.streamlit.io
# 3. CrÃ©er une nouvelle app
# 4. Pointer vers app/streamlit_app.py
```

### Option 2: Docker

```bash
# Build l'image
docker-compose build

# Lancer les services
docker-compose up -d

# Services disponibles:
# - API: http://localhost:8000
# - App: http://localhost:8501
```

### Option 3: Heroku

```bash
# 1. CrÃ©er une app Heroku
heroku create mon-app-classification

# 2. DÃ©ployer
git push heroku main

# 3. Ouvrir l'app
heroku open
```

### Option 4: AWS / GCP / Azure

Voir la documentation de dÃ©ploiement dans `docs/deployment.md`

## ğŸ“ˆ RÃ©sultats

### Comparaison des modalitÃ©s

| ModalitÃ© | ModÃ¨le | Accuracy | F1-Score | Temps infÃ©rence |
|----------|--------|----------|----------|-----------------|
| **Texte** | SVM (TF-IDF) | **94.94%** | **0.949** | ~10ms |
| **Image** | CNN | 62.50% | 0.6202 | ~50ms |
| **Multimodal** | Late Fusion | XX.X% | 0.XXX | ~60ms |

### Matrice de confusion (Texte)

```
                    Predicted
                BC  BP  CO  HD  HF  KD  WA
Actual    BC   [145   2   0   1   1   0   1]
          BP   [  1 143   0   2   2   1   1]
          CO   [  0   0 148   0   1   1   0]
          HD   [  2   1   0 141   3   3   0]
          HF   [  1   2   1   2 140   4   0]
          KD   [  0   1   1   3   3 142   0]
          WA   [  0   0   0   0   0   0 150]
```

## ğŸ¤ Contributions

Les contributions sont les bienvenues ! 

### Comment contribuer

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push sur la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

### Guidelines

- Suivre PEP 8 pour le code Python
- Ajouter des tests pour les nouvelles fonctionnalitÃ©s
- Mettre Ã  jour la documentation
- Utiliser des messages de commit clairs

## ğŸ“ TODO

- [ ] Ajouter support de nouvelles catÃ©gories
- [ ] ImplÃ©menter BERT pour le texte
- [ ] Tester Vision Transformer pour les images
- [ ] Ajouter authentification API
- [ ] CrÃ©er dashboard admin
- [ ] ImplÃ©menter A/B testing
- [ ] Ajouter monitoring (Prometheus/Grafana)
- [ ] CrÃ©er documentation API complÃ¨te

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ‘¥ Auteurs

- **Awa GUEYE** - *Travail initial* - [GitHub](https://github.com/awa-gueye)

## ğŸ™ Remerciements

- Dataset : [Flipkart Products](https://www.kaggle.com/datasets/...)
- Frameworks : TensorFlow, Scikit-learn, Streamlit, FastAPI
- Inspiration : Projets e-commerce et classification multimodale

---

<div align="center">

Made with â¤ï¸ using Python, TensorFlow & Streamlit

[â¬† Retour en haut](#Projet_NLP)

</div>
