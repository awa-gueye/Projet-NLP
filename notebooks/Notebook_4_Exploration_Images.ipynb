{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š NOTEBOOK 4 : EXPLORATION ET FEATURE ENGINEERING DES IMAGES\n",
    "\n",
    "## Objectifs\n",
    "- âœ… Analyse statistique complÃ¨te (taille, qualitÃ©, couleurs)\n",
    "- âœ… DÃ©tection d'images problÃ©matiques\n",
    "- âœ… Feature engineering (HOG, couleurs, textures)\n",
    "- âœ… Visualisation sÃ©parabilitÃ© classes (PCA, UMAP)\n",
    "- âœ… Recommandations preprocessing\n",
    "\n",
    "## Dataset\n",
    "- 7 catÃ©gories produits e-commerce\n",
    "- ~150 images/catÃ©gorie\n",
    "- Total: ~1050 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Computer Vision\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage import feature\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "\n",
    "# Dimensionality reduction\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import umap\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"âœ… Imports rÃ©ussis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins - ADAPTER Ã€ VOTRE STRUCTURE\n",
    "BASE_DIR = Path.cwd().parent\n",
    "DATA_DIR = BASE_DIR / \"Data\"\n",
    "IMAGES_DIR = DATA_DIR / \"Images\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\" / \"exploration\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "METADATA_FILE = DATA_DIR / \"data_images_corrected.csv\"\n",
    "\n",
    "# CatÃ©gories\n",
    "CATEGORIES = [\n",
    "    \"Baby Care\",\n",
    "    \"Beauty and Personal Care\",\n",
    "    \"Computers\",\n",
    "    \"Home Decor & Festive Needs\",\n",
    "    \"Home Furnishing\",\n",
    "    \"Kitchen & Dining\",\n",
    "    \"Watches\"\n",
    "]\n",
    "\n",
    "print(f\"ðŸ“‚ Images: {IMAGES_DIR}\")\n",
    "print(f\"ðŸ“‚ Results: {RESULTS_DIR}\")\n",
    "print(f\"\\nðŸ“¦ {len(CATEGORIES)} catÃ©gories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CHARGEMENT DES DONNÃ‰ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger mÃ©tadonnÃ©es\n",
    "df = pd.read_csv(METADATA_FILE)\n",
    "\n",
    "print(f\"âœ… Dataset: {df.shape[0]} images\")\n",
    "print(f\"\\nðŸ“Š Distribution:\")\n",
    "print(df['main_category'].value_counts())\n",
    "\n",
    "# VÃ©rifier images prÃ©sentes\n",
    "valid_idx = []\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"VÃ©rification\"):\n",
    "    if (IMAGES_DIR / row['image']).exists():\n",
    "        valid_idx.append(idx)\n",
    "\n",
    "df = df.loc[valid_idx].reset_index(drop=True)\n",
    "print(f\"\\nâœ… {len(df)} images valides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ANALYSE STATISTIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image(img_path):\n",
    "    \"\"\"Analyser propriÃ©tÃ©s d'une image\"\"\"\n",
    "    try:\n",
    "        # Taille\n",
    "        with Image.open(img_path) as img:\n",
    "            w, h = img.size\n",
    "        \n",
    "        # QualitÃ© (OpenCV)\n",
    "        img_gray = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "        sharpness = cv2.Laplacian(img_gray, cv2.CV_64F).var()\n",
    "        brightness = np.mean(img_gray)\n",
    "        contrast = np.std(img_gray)\n",
    "        \n",
    "        # Couleurs\n",
    "        img_rgb = cv2.cvtColor(cv2.imread(str(img_path)), cv2.COLOR_BGR2RGB)\n",
    "        avg_color = np.mean(img_rgb, axis=(0,1))\n",
    "        \n",
    "        return {\n",
    "            'width': w, 'height': h, 'aspect_ratio': w/h,\n",
    "            'sharpness': sharpness, 'brightness': brightness, 'contrast': contrast,\n",
    "            'avg_r': avg_color[0], 'avg_g': avg_color[1], 'avg_b': avg_color[2]\n",
    "        }\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Analyser\n",
    "stats = []\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Analyse\"):\n",
    "    s = analyze_image(IMAGES_DIR / row['image'])\n",
    "    if s:\n",
    "        s['category'] = row['main_category']\n",
    "        s['filename'] = row['image']\n",
    "        stats.append(s)\n",
    "\n",
    "stats_df = pd.DataFrame(stats)\n",
    "print(f\"\\nâœ… {len(stats_df)} images analysÃ©es\")\n",
    "print(f\"\\n{stats_df.describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisations des distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Largeur\n",
    "axes[0,0].hist(stats_df['width'], bins=30, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('Largeurs', fontweight='bold')\n",
    "axes[0,0].set_xlabel('Pixels')\n",
    "\n",
    "# Hauteur\n",
    "axes[0,1].hist(stats_df['height'], bins=30, color='lightcoral', edgecolor='black')\n",
    "axes[0,1].set_title('Hauteurs', fontweight='bold')\n",
    "axes[0,1].set_xlabel('Pixels')\n",
    "\n",
    "# Aspect ratio\n",
    "axes[0,2].hist(stats_df['aspect_ratio'], bins=30, color='lightgreen', edgecolor='black')\n",
    "axes[0,2].set_title('Ratios d\\'Aspect', fontweight='bold')\n",
    "\n",
    "# NettetÃ©\n",
    "axes[1,0].hist(stats_df['sharpness'], bins=30, color='gold', edgecolor='black')\n",
    "axes[1,0].axvline(100, color='red', linestyle='--', label='Seuil (100)')\n",
    "axes[1,0].set_title('NettetÃ© (Laplacian)', fontweight='bold')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# LuminositÃ©\n",
    "axes[1,1].hist(stats_df['brightness'], bins=30, color='orange', edgecolor='black')\n",
    "axes[1,1].axvline(50, color='red', linestyle='--', label='Min')\n",
    "axes[1,1].axvline(200, color='red', linestyle='--', label='Max')\n",
    "axes[1,1].set_title('LuminositÃ©', fontweight='bold')\n",
    "axes[1,1].legend()\n",
    "\n",
    "# Contraste\n",
    "axes[1,2].hist(stats_df['contrast'], bins=30, color='purple', edgecolor='black')\n",
    "axes[1,2].axvline(30, color='red', linestyle='--', label='Seuil')\n",
    "axes[1,2].set_title('Contraste', fontweight='bold')\n",
    "axes[1,2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DÃ©tection images problÃ©matiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seuils qualitÃ© (basÃ©s sur recherche)\n",
    "stats_df['is_blurry'] = stats_df['sharpness'] < 50\n",
    "stats_df['bad_exposure'] = (stats_df['brightness'] < 50) | (stats_df['brightness'] > 200)\n",
    "stats_df['low_contrast'] = stats_df['contrast'] < 30\n",
    "\n",
    "print(\"âš ï¸ IMAGES PROBLÃ‰MATIQUES\")\n",
    "print(f\"Floues: {stats_df['is_blurry'].sum()}\")\n",
    "print(f\"Mauvaise exposition: {stats_df['bad_exposure'].sum()}\")\n",
    "print(f\"Faible contraste: {stats_df['low_contrast'].sum()}\")\n",
    "\n",
    "if stats_df['is_blurry'].sum() > 0:\n",
    "    print(\"\\nðŸ“‹ Exemples floues:\")\n",
    "    print(stats_df[stats_df['is_blurry']][['filename','category','sharpness']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse par catÃ©gorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_stats = stats_df.groupby('category').agg({\n",
    "    'sharpness': 'mean',\n",
    "    'brightness': 'mean',\n",
    "    'contrast': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"ðŸ“Š QUALITÃ‰ PAR CATÃ‰GORIE\")\n",
    "print(cat_stats)\n",
    "\n",
    "# Graphique\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "cat_stats['sharpness'].plot(kind='barh', ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('NettetÃ© par CatÃ©gorie', fontweight='bold')\n",
    "axes[0].axvline(100, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "cat_stats['brightness'].plot(kind='barh', ax=axes[1], color='gold')\n",
    "axes[1].set_title('LuminositÃ© par CatÃ©gorie', fontweight='bold')\n",
    "\n",
    "cat_stats['contrast'].plot(kind='barh', ax=axes[2], color='coral')\n",
    "axes[2].set_title('Contraste par CatÃ©gorie', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'quality_by_category.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img_path, size=(128,128)):\n",
    "    \"\"\"Features: HOG + Couleurs + Textures\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        img_resized = cv2.resize(img_rgb, size)\n",
    "        gray_resized = cv2.resize(img_gray, size)\n",
    "        \n",
    "        # HOG (forme)\n",
    "        hog_feat = feature.hog(\n",
    "            gray_resized, orientations=9,\n",
    "            pixels_per_cell=(8,8), cells_per_block=(2,2),\n",
    "            feature_vector=True\n",
    "        )[:200]  # Tronquer\n",
    "        \n",
    "        # Histogramme couleurs (3 canaux Ã— 32 bins)\n",
    "        color_hist = []\n",
    "        for ch in range(3):\n",
    "            hist = cv2.calcHist([img_resized], [ch], None, [32], [0,256])\n",
    "            color_hist.extend((hist / hist.sum()).flatten())\n",
    "        \n",
    "        # LBP (texture)\n",
    "        lbp = feature.local_binary_pattern(gray_resized, 8, 1, 'uniform')\n",
    "        lbp_hist, _ = np.histogram(lbp.ravel(), bins=10, range=(0,10), density=True)\n",
    "        \n",
    "        # Moments couleur\n",
    "        moments = []\n",
    "        for ch in range(3):\n",
    "            moments.append(np.mean(img_resized[:,:,ch]))\n",
    "            moments.append(np.std(img_resized[:,:,ch]))\n",
    "        \n",
    "        return np.concatenate([hog_feat, color_hist, lbp_hist, moments])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Extraction\n",
    "print(\"ðŸ”§ Extraction features...\")\n",
    "features, labels, files = [], [], []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Features\"):\n",
    "    feat = extract_features(IMAGES_DIR / row['image'])\n",
    "    if feat is not None:\n",
    "        features.append(feat)\n",
    "        labels.append(row['main_category'])\n",
    "        files.append(row['image'])\n",
    "\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(f\"\\nâœ… Features: {X.shape}\")\n",
    "\n",
    "# Sauvegarder\n",
    "np.save(RESULTS_DIR / 'features.npy', X)\n",
    "np.save(RESULTS_DIR / 'labels.npy', y)\n",
    "np.save(RESULTS_DIR / 'files.npy', np.array(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. VISUALISATION SÃ‰PARABILITÃ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š PCA...\")\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "print(f\"Variance: {pca.explained_variance_ratio_.sum():.2%}\")\n",
    "\n",
    "# Visualisation\n",
    "label_map = {cat: i for i, cat in enumerate(CATEGORIES)}\n",
    "y_num = np.array([label_map[l] for l in y])\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=y_num, cmap='tab10', alpha=0.6, s=50)\n",
    "plt.colorbar(scatter, label='CatÃ©gorie')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})', fontweight='bold')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})', fontweight='bold')\n",
    "plt.title('PCA - SÃ©parabilitÃ© des Classes', fontweight='bold', fontsize=14)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'pca.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š UMAP...\")\n",
    "\n",
    "reducer = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, \n",
    "                    metric='cosine', random_state=42)\n",
    "X_umap = reducer.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "scatter = plt.scatter(X_umap[:,0], X_umap[:,1], c=y_num, cmap='tab10', alpha=0.6, s=50)\n",
    "plt.colorbar(scatter, label='CatÃ©gorie')\n",
    "plt.xlabel('UMAP 1', fontweight='bold')\n",
    "plt.ylabel('UMAP 2', fontweight='bold')\n",
    "plt.title('UMAP - SÃ©parabilitÃ© des Classes', fontweight='bold', fontsize=14)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'umap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_pca = silhouette_score(X_pca, y_num)\n",
    "sil_umap = silhouette_score(X_umap, y_num)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Š SÃ‰PARABILITÃ‰\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Silhouette PCA:  {sil_pca:.3f}\")\n",
    "print(f\"Silhouette UMAP: {sil_umap:.3f}\")\n",
    "print(\"\\nInterprÃ©tation:\")\n",
    "print(\"  > 0.5 : Excellente sÃ©paration\")\n",
    "print(\"  0.3-0.5: Bonne sÃ©paration\")\n",
    "print(\"  < 0.3 : Faible sÃ©paration\")\n",
    "\n",
    "if sil_umap > 0.5:\n",
    "    print(\"\\nâœ… Classes bien sÃ©parÃ©es !\")\n",
    "elif sil_umap > 0.3:\n",
    "    print(\"\\nâœ… SÃ©paration acceptable\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Augmentation donnÃ©es critique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. RECOMMANDATIONS PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“‹ RECOMMANDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "median_w = stats_df['width'].median()\n",
    "median_h = stats_df['height'].median()\n",
    "\n",
    "print(f\"\\n1. REDIMENSIONNEMENT\")\n",
    "print(f\"   Actuel: {median_w:.0f} Ã— {median_h:.0f}\")\n",
    "print(f\"   RecommandÃ©: 224 Ã— 224\")\n",
    "print(f\"   Pourquoi: Standard Transfer Learning\")\n",
    "\n",
    "print(f\"\\n2. NORMALISATION\")\n",
    "print(f\"   Mean: [0.485, 0.456, 0.406]\")\n",
    "print(f\"   Std:  [0.229, 0.224, 0.225]\")\n",
    "print(f\"   Pourquoi: Stats ImageNet\")\n",
    "\n",
    "print(f\"\\n3. AUGMENTATION (critique pour 150 img/classe)\")\n",
    "print(f\"   - Rotation: Â±15Â°\")\n",
    "print(f\"   - Translation: Â±20%\")\n",
    "print(f\"   - Flip horizontal: 50%\")\n",
    "print(f\"   - Zoom: Â±20%\")\n",
    "print(f\"   - Color jitter: Â±20%\")\n",
    "print(f\"   - MixUp alpha: 0.2\")\n",
    "\n",
    "n_prob = (stats_df['is_blurry'] | stats_df['bad_exposure']).sum()\n",
    "print(f\"\\n4. IMAGES PROBLÃ‰MATIQUES: {n_prob}\")\n",
    "if n_prob > 0:\n",
    "    print(f\"   â†’ Inspecter et retirer si nÃ©cessaire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. SAUVEGARDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats complÃ¨tes\n",
    "stats_df.to_csv(RESULTS_DIR / 'stats.csv', index=False)\n",
    "\n",
    "# Embeddings\n",
    "np.save(RESULTS_DIR / 'pca.npy', X_pca)\n",
    "np.save(RESULTS_DIR / 'umap.npy', X_umap)\n",
    "\n",
    "# MÃ©triques\n",
    "metrics = {\n",
    "    'n_images': len(stats_df),\n",
    "    'n_categories': len(CATEGORIES),\n",
    "    'median_width': float(median_w),\n",
    "    'median_height': float(median_h),\n",
    "    'silhouette_pca': float(sil_pca),\n",
    "    'silhouette_umap': float(sil_umap),\n",
    "    'n_blurry': int(stats_df['is_blurry'].sum()),\n",
    "    'n_bad_exposure': int(stats_df['bad_exposure'].sum())\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… EXPLORATION TERMINÃ‰E\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nRÃ©sultats: {RESULTS_DIR}\")\n",
    "print(\"\\nðŸŽ¯ PrÃªt pour Notebook 5 (Deep Learning)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
